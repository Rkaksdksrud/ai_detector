# human ë°ì´í„°ì˜ ìš”ì•½ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ ì—ì„¸ì´ ì‘ì„± í”„ë¡œê·¸ë¨ -> AI ë°ì´í„°ë¡œ í™œìš©


import json
import os
import glob
import requests

# 1. ê²½ë¡œ ì„¤ì •
BASE_DIR = '/home/ktg0310/projects/ml_project/AI-dectector'
# 'ë¼ë²¨ë§ë°ì´í„°' í´ë”ê¹Œì§€ë§Œ ì§€ì •í•˜ë©´ í•˜ìœ„ 01~10 í´ë”ë¥¼ ëª¨ë‘ ë’¤ì§‘ë‹ˆë‹¤.
HUMAN_ROOT = os.path.join(BASE_DIR, 'data/human/1.Training/ë¼ë²¨ë§ë°ì´í„°/TL1')
OUTPUT_PATH = os.path.join(BASE_DIR, 'data/processed/combined_ai_human_data.json')

def ask_llama3(summary_text):
    """ë¡œì»¬ Ollama(Llama3)ë¥¼ ì‚¬ìš©í•˜ì—¬ ìš”ì•½ë¬¸ì„ ê¸´ ì—ì„¸ì´ë¡œ í™•ì¥í•©ë‹ˆë‹¤."""
    url = "http://localhost:11434/api/generate"
    prompt = f"""
    ë‹¹ì‹ ì€ ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ 'ìš”ì•½ ë‚´ìš©'ì„ ë°”íƒ•ìœ¼ë¡œ ì•½ 800ì ë‚´ì™¸ì˜ í•œêµ­ì–´ ì—ì„¸ì´ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    
    [ìš”ì•½ ë‚´ìš©]: {summary_text}
    
    [ì‘ì„± ê°€ì´ë“œ]:
    1. ë…¼ë¦¬ì ì¸ ì„œë¡ -ë³¸ë¡ -ê²°ë¡  êµ¬ì¡°ë¥¼ ê°–ì¶œ ê²ƒ.
    2. ì „ë¬¸ì ì´ê³  ë¶„ì„ì ì¸ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•  ê²ƒ.
    3. í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•  ê²ƒ.
    
    ì—ì„¸ì´ ì‹œì‘:
    """
    payload = {
        "model": "llama3",
        "prompt": prompt,
        "stream": False,
        "options": {"num_predict": 1500, "temperature": 0.7}
    }
    try:
        response = requests.post(url, json=payload, timeout=120)
        return response.json().get('response', '').strip()
    except:
        return None

# 2. ë©”ì¸ ì‹¤í–‰ ë¡œì§
def main():
    # ëª¨ë“  í•˜ìœ„ í´ë”ì˜ JSON íŒŒì¼ ë¦¬ìŠ¤íŠ¸ í™•ë³´
    json_files = glob.glob(os.path.join(HUMAN_ROOT, '**/*.json'), recursive=True)
    print(f"ğŸ” ì´ {len(json_files)}ê°œì˜ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")

    dataset = []
    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìš°ì„  100ê°œë§Œ ì§„í–‰ (ì„±ê³µ ì‹œ [:100] ì œê±°)
    for i, file_path in enumerate(json_files[:100]):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # 1) ì¸ê°„ ë°ì´í„° ì¶”ì¶œ (passage)
            passage = data.get('Meta(Refine)', {}).get('passage', '')
            
            # 2) AI ì—ì„¸ì´ ìƒì„±ì„ ìœ„í•œ ìš”ì•½ë¬¸ ì¶”ì¶œ (summary1)
            summary = data.get('Annotation', {}).get('summary1', '')

            if len(passage) >= 300 and summary:
                print(f"[{i+1}/100] ì—ì„¸ì´ ìƒì„± ì¤‘... ({os.path.basename(file_path)})")
                
                # Llama3ë¡œ AI ë°ì´í„° ìƒì„±
                ai_essay = ask_llama3(summary)
                
                if ai_essay and len(ai_essay) >= 300:
                    # ì¸ê°„ ë°ì´í„° ì €ì¥ (Label 0)
                    dataset.append({'text': passage, 'label': 0, 'source': 'human'})
                    # ìƒì„±ëœ AI ë°ì´í„° ì €ì¥ (Label 1)
                    dataset.append({'text': ai_essay, 'label': 1, 'source': 'llama3'})
                    print(f"   âœ… ì™„ë£Œ (ì¸ê°„: {len(passage)}ì / AI: {len(ai_essay)}ì)")
                
        except Exception as e:
            print(f"   âŒ ì˜¤ë¥˜ ë°œìƒ ({file_path}): {e}")

        # 10ê±´ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
        if (i + 1) % 10 == 0:
            with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
                json.dump(dataset, f, ensure_ascii=False, indent=4)

    print(f"âœ¨ ì‘ì—… ì™„ë£Œ! ì´ {len(dataset)}ê±´ì˜ ë°ì´í„°ê°€ {OUTPUT_PATH}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()